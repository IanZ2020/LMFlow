prune_ckpt_path='test-save-grad-7b'
echo "[START] - Start Pruning Model"
deepspeed --master_port=42477 --include localhost:4,5,6,7 examples/prune_model_save_grad.py --model_name_or_path /home/zhangyihan/.cache/huggingface/hub/models--pinkmanlove--llama-7b-hf/snapshots/b3cde76468bad3c085ead29707ee7481121a4ca0 --pruning_ratio 0.25 --block_wise --device gpu --block_mlp_layer_start 0 --block_mlp_layer_end 0 --block_attention_layer_start 2 --block_attention_layer_end 3 --output_dir $prune_ckpt_path --pruner_type taylor --test_after_train --taylor param_first --save_model --global_pruning --grouping_strategy sum --num_examples 16384 --prune_block_size 1024 --block_size 1024 --prune_batch_size 1 --torch_dtype float16 --deepspeed configs/ds_config_zero3_for_eval.json --dataset_path data/wikitext-103-raw-v1/test --pruning_dataset redpajama --iterative_steps 1
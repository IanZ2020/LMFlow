
data=$1
grad_info_path=grad_info/7b_$data'_first_grad_info.bin'

prune_ckpt_path_old=7b-mlp/llama-7b-$data-mlp-0-31-0.2-first-local-weighted-expt-0.1
echo "[START] - Start Pruning Model"
deepspeed --master_port=43477 --include localhost:2,3 examples/prune_with_layer_importance.py --model_name_or_path /home/zhangyihan/.cache/huggingface/hub/models--pinkmanlove--llama-7b-hf/snapshots/b3cde76468bad3c085ead29707ee7481121a4ca0 --pruning_ratio 0.2 --block_wise --device gpu --block_mlp_layer_start 0 --block_mlp_layer_end 31 --block_attention_layer_start 1 --block_attention_layer_end 1 --output_dir $prune_ckpt_path_old --pruner_type taylor --test_after_train --taylor param_first --save_model --grouping_strategy sum --num_examples 8192 --prune_block_size 1024 --block_size 1024 --prune_batch_size 1 --torch_dtype float16 --deepspeed configs/ds_config_zero3_for_eval.json --dataset_path data/wikitext-103-raw-v1/test --pruning_dataset wikitext_cat --layer_importance "0.4433959030667942, 0.42943772981979894, 0.4387108761845347, 0.44664810517274084, 0.4868734052140721, 0.4806382750376273, 0.463484776612138, 0.45582083400050505, 0.4445599522965959, 0.4248513848689805, 0.40778876206955805, 0.40778876206955805, 0.4004132198053369, 0.38499582666287996, 0.3720061916921988, 0.3664645205800983, 0.3664645205800983, 0.34845900821347475, 0.3260966083675537, 0.3074776639800238, 0.29431870450315556, 0.27509277764804363, 0.25643629057178713, 0.24057976478957635, 0.22362480490807765, 0.2167571626568568, 0.2125318091054341, 0.2125318091054341, 0.21441986549960387, 0.2302910539796431, 0.33074705991885944, 0.8201657643526981" --layer_importance_weighting_type exp --grad_info_path $grad_info_path --exp_t 0.1
echo "[FINISH] - Finish Pruning Model"

prune_ckpt_path=7b-mha+mlp/llama-7b-$data-mlp-0-31-0.2-first-local-weighted-expt-0.1-7b-mha-1-32-0.2-first-local-weighted-expt-0.05
echo "[START] - Start Pruning Model"
deepspeed --master_port=43477 --include localhost:2,3 examples/prune_with_layer_importance.py --model_name_or_path /home/zhangyihan/LMFlow/prune_log/$prune_ckpt_path_old --arch_type pruned_decoder_only --pruning_ratio 0.2 --block_wise --device gpu --block_mlp_layer_start 0 --block_mlp_layer_end 0 --block_attention_layer_start 1 --block_attention_layer_end 32 --output_dir $prune_ckpt_path --pruner_type taylor --test_after_train --taylor param_first --save_model --grouping_strategy sum --num_examples 8192 --prune_block_size 1024 --block_size 1024 --prune_batch_size 1 --torch_dtype float16 --deepspeed configs/ds_config_zero3_for_eval.json --dataset_path data/wikitext-103-raw-v1/test --pruning_dataset wikitext_cat --layer_importance "1.0227742260672568, 0.4187449028014783, 0.3889704304385315, 0.3216977340098863, 0.33805956583531876, 0.3425536000754512, 0.3322832713343088, 0.33381267411130283, 0.34699170049673717, 0.32327538993145327, 0.33805956583531876, 0.3395639288119467, 0.32011257416441, 0.28557439117210426, 0.26420658436860583, 0.27324603799606223, 0.25045400186741446, 0.23420131211473263, 0.20773775029228278, 0.19055113095391613, 0.17686565285763697, 0.15954292888895208, 0.12090408592752845, 0.14641814300826347, 0.11668522333218645, 0.12090408592752845, 0.09903541693516447, 0.09903541693516447, 0.12090408592752845, 0.11668522333218645, 0.11668522333218645, 0.15954292888895208" --layer_importance_weighting_type exp --grad_info_path $grad_info_path --exp_t 0.05
echo "[FINISH] - Finish Pruning Model"
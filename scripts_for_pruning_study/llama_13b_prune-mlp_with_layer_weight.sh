prune_ckpt_path='13b-mha/llama-13b-mha-1-40-0.25-8192Redpajama-second-local-weighted-expt-0.05'
echo "[START] - Start Pruning Model"
deepspeed --master_port=43475 --include localhost:0,1,2,3,4,5,6,7 examples/prune_with_layer_importance.py --model_name_or_path pinkmanlove/llama-13b-hf --pruning_ratio 0.25 --block_wise --device gpu --block_mlp_layer_start 0 --block_mlp_layer_end 0 --block_attention_layer_start 1 --block_attention_layer_end 40 --output_dir $prune_ckpt_path --pruner_type taylor --test_after_train --taylor param_second --save_model --grouping_strategy sum --num_examples 8192 --prune_block_size 1024 --block_size 1024 --prune_batch_size 1 --torch_dtype float16 --deepspeed configs/ds_config_zero3_for_eval.json --dataset_path data/wikitext-103-raw-v1/test --pruning_dataset wikitext_cat --layer_importance "1.0768547568863311, 0.4172668474640083, 0.39783996984715886, 0.3260966083675537, 0.3239043758049637, 0.30548898393562524, 0.3472856378477182, 0.32232969066110284, 0.3204302117906909, 0.30714708330335966, 0.29431870450315556, 0.3074776639800238, 0.31531093554610834, 0.28734394299515853, 0.25683026197202274, 0.2463868618217987, 0.20033484232311968, 0.21814770772210607, 0.1900224234627107, 0.18356062695487216, 0.17108866494489416, 0.1681265009157972, 0.15312012572889822, 0.13648773466080505, 0.11839072552777699, 0.11923437096925123, 0.10492901480724003, 0.10103802160852246, 0.10775542078717872, 0.08248549466933483, 0.08487829022786185, 0.08369042447459077, 0.07350123639177734, 0.07212665871195886, 0.08720560886095623, 0.08248549466933483, 0.07350123639177734, 0.0949039414973622, 0.12336649646075368, 0.11319751182365446" --layer_importance_weighting_type exp --grad_info_path /home/zhangyihan/LMFlow/grad_info/13b_8192red_second_grad_info.bin --exp_t 0.05
echo "[FINISH] - Finish Pruning Model"


prune_ckpt_path='13b-mha+mlp/llama-13b-mha-1-40-0.25-8192Redpajama-second-local-weighted-expt-0.05-mlp-new-0-39-0.25-8192Redpajama-second-local-weighted-expt-0.1'
echo "[START] - Start Pruning Model"
deepspeed --master_port=43475 --include localhost:0,1,2,3,4,5,6,7 examples/prune_with_layer_importance.py --model_name_or_path /home/zhangyihan/LMFlow/prune_log/13b-mha/llama-13b-mha-1-40-0.25-8192Redpajama-second-local-weighted-expt-0.05 --arch_type pruned_decoder_only --pruning_ratio 0.25 --block_wise --device gpu --block_mlp_layer_start 0 --block_mlp_layer_end 39 --block_attention_layer_start 1 --block_attention_layer_end 1 --output_dir $prune_ckpt_path --pruner_type taylor --test_after_train --taylor param_second --save_model --grouping_strategy sum --num_examples 8192 --prune_block_size 1024 --block_size 1024 --prune_batch_size 1 --torch_dtype float16 --deepspeed configs/ds_config_zero3_for_eval.json --dataset_path data/wikitext-103-raw-v1/test --pruning_dataset wikitext_cat --layer_importance "0.4978736577094003, 0.4361140674643581, 0.4496483553053778, 0.45079734169931884, 0.4668287905515154, 0.4580872943100168, 0.4690458582650856, 0.4436289409935888, 0.421930641099489, 0.41230398380200584, 0.3962884299342177, 0.3790948331596482, 0.3801742192426452, 0.3739272644602526, 0.35856891362309845, 0.3395639288119467, 0.3197946319043285, 0.3074776639800238, 0.299107026195814, 0.2905027218465317, 0.27983870714867987, 0.2680091815368411, 0.252863536299927, 0.24183564898036344, 0.2258683730893185, 0.21205720842323728, 0.2028320837670698, 0.19524586236593036, 0.18519696790474272, 0.17912481487888987, 0.175152362064083, 0.17108866494489416, 0.1681265009157972, 0.16931752556572385, 0.16990993689494324, 0.17629638681133347, 0.1857392477529288, 0.2072523353624738, 0.2769275124497905, 0.7263552809377891" --layer_importance_weighting_type exp --grad_info_path /home/zhangyihan/LMFlow/grad_info/13b_8192red_second_grad_info.bin --exp_t 0.1
echo "[FINISH] - Finish Pruning Model"

